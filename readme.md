
***

# **互联网用户需求智能分析方案**

## 1. 整体设计思路

针对需求中提到的“先打标后分析”、“统计提及率”以及“需求可追溯”等要点，设计了一个**三步走的混合分析流程**：

1.  **规则预处理**：利用关键词和正则表达式，对海量评论进行快速、粗粒度的初步筛选和分类，识别出评论涉及的产品模块（如外观、动力等），保证后续分析的效率和准确性。
2.  **LLM 深度分析**：对上一步筛选出的有效评论，调用大语言模型（LLM）进行逐条深度分析，提取情感、细分主题，并按照 **4W1H 框架（When, Where, Why, Who, How）** 将其转化为结构化的原始需求。
3.  **聚合与报告生成**：将所有结构化分析结果进行汇总统计，计算各主题的提及率、情感分布等，并再次利用 LLM 的归纳能力，将分散的“Why”和“How”提炼成几条核心的用户原始需求，最终生成一份全面的分析报告。

此设计兼顾了处理效率（规则预处理）和分析深度（LLM），同时通过标准化的标签和结构化输出，确保了统计的准确性和历史数据的可比性。

## 2. 实现流程详解

整个流程由 `main.py` 主脚本按顺序调用以下三个核心模块完成：

### **第一步：关键词初步打标 (`tag_process.py`)**

* **目标**：从原始数据中快速筛选出与产品相关的评论，并打上初步的大类标签。
* **输入**：
    * `input_data.csv`：包含用户评论的原始数据文件。
    * `keywords.yaml`：可灵活配置的关键词库，定义了如“价格”、“外观”、“内饰”等14个核心大类及其相关的海量关键词。
* **处理逻辑**：
    1.  加载 `keywords.yaml`，将关键词整合成匹配规则。
    2.  读取CSV文件中的每一条评论。
    3.  通过正则表达式，判断评论是否命中了某个或某几个大类的关键词。
    4.  为命中的评论添加对应的标签（如：`外观`、`动力`）。
* **输出**：`output_tagged.csv`。这是一个增加了“标签”列的新CSV文件，为下一步的LLM分析提供了上下文。

### **第二步：LLM 深度分析与结构化 (`llm_tag.py`)**

* **目标**：对已打上初步标签的评论，进行精细化的情感、主题及4W1H分析。
* **输入**：
    * `output_tagged.csv`：上一步的输出文件。
    * `topics.yaml`：细分主题库，将每个大类进一步拆解为更具体的主题（如“外观” -> “整体造型”、“车灯设计”等）。
    * `config.yaml`：配置文件，包含LLM的API Key、模型名称等信息。
* **处理逻辑**：
    1.  针对每一条带有标签的评论，根据其大类标签（如 `外观`），从 `topics.yaml` 中获取对应的候选细分主题列表。
    2.  构造一个精密的Prompt，要求LLM完成三项任务：
        * **情感判断**：正面、负面或中性。
        * **主题提炼**：从候选列表中选择最匹配的细分主题。
        * **4W1H分析**：提取需求发生的时间、地点、原因、人物和建议方式。
    3.  要求LLM以严格的JSON格式返回结果，确保数据结构统一。
    4.  利用多线程并发处理，提高API调用效率。
* **输出**：`output_analysis.json`。一个JSON文件，每条记录都包含了原始评论、标签以及LLM分析出的完整结构化数据。

### **第三步：聚合统计与需求提炼 (`generate_report.py`)**

* **目标**：将离散的单条分析结果，聚合成一份具备洞察力的最终报告。
* **输入**：`output_analysis.json`：上一步的输出文件。
* **处理逻辑**：
    1.  **数据统计**：读取JSON数据，以“细分主题”为核心进行聚合。计算每个主题的**提及总数**、**提及率**以及**情感分布**（正面/负面/中性数量）。
    2.  **需求归纳**：对于每一个高频主题，收集其下所有评论的`why`（核心痛点）和`how`（解决方案）列表。
    3.  再次调用LLM，将这些零散的痛点和建议，智能归纳总结为**1-3条最核心的用户原始需求**。
    4.  将统计数据和归纳后的需求整合，生成最终报告。
* **输出**：`final_report.json`。最终的分析报告，包含了元数据、按提及率排序的各主题分析（含统计数据）以及提炼出的核心原始需求列表。

## 3. 方案特点与优势

* **混合策略，兼顾效率与深度**：规则匹配快速过滤，LLM保证分析质量。
* **高度可配置**：所有关键词、主题、模型参数均在 `.yaml` 文件中配置，非技术人员也可轻松维护和扩展，满足了“新增补充机制”的需求。
* **标准化与可追溯**：通过固定的细分主题库和4W1H框架，保证了标签体系的一致性，便于进行历史数据对比和趋势分析。
* **数据驱动决策**：报告明确给出了各需求的**提及率**和**情感倾向**，为产品决策的优先级排序提供了量化依据。
* **端到端自动化**：通过 `main.py` 一键执行，实现了从原始数据到洞察报告的全流程自动化。